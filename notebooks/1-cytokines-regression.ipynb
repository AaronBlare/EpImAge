{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Debugging autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "import numpy as np\n",
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.models import CategoryEmbeddingModelConfig, GANDALFConfig, TabNetModelConfig, FTTransformerConfig, DANetConfig\n",
    "from pytorch_tabular.config import DataConfig, OptimizerConfig, TrainerConfig\n",
    "import pandas as pd\n",
    "from src.utils.configs import read_parse_config\n",
    "from src.pt.hyper_opt import train_hyper_opt\n",
    "import optuna\n",
    "import pathlib\n",
    "import os\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import distinctipy\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.patheffects as pe\n",
    "from plottable import ColumnDefinition, Table\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "path_root = pathlib.Path(os.getcwd())\n",
    "path_plots = f\"{path_root}/plots\"\n",
    "path_data = f\"{path_root}/data/immuno-regression\"\n",
    "df_feats = pd.read_excel(f\"{path_data}/features.xlsx\")\n",
    "imms = df_feats.columns.to_list()\n",
    "df = pd.read_excel(f\"{path_data}/data.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_n_splits = 5\n",
    "tst_n_repeats = 5\n",
    "tst_random_state = seed\n",
    "\n",
    "val_n_splits = 4\n",
    "val_n_repeats = 4\n",
    "val_random_state = seed\n",
    "\n",
    "stratify_cat_parts_all = {\n",
    "    'Control': df.index[df['Status'] == 'Control'].values,\n",
    "    'ESRD': df.index[df['Status'] == 'ESRD'].values,\n",
    "}\n",
    "\n",
    "for part_all, ids_all in stratify_cat_parts_all.items():\n",
    "    trgt_all = df.loc[ids_all, 'Age'].values\n",
    "    ptp_all = np.ptp(trgt_all)\n",
    "    num_bins_all = 5\n",
    "    bins_all = np.linspace(np.min(trgt_all) - 0.1 * ptp_all, np.max(trgt_all) + 0.1 * ptp_all, num_bins_all + 1)\n",
    "    binned_all = np.digitize(trgt_all, bins_all) - 1\n",
    "    unique_all, counts_tst = np.unique(binned_all, return_counts=True)\n",
    "    \n",
    "    k_fold_all = RepeatedStratifiedKFold(\n",
    "        n_splits=tst_n_splits,\n",
    "        n_repeats=tst_n_repeats,\n",
    "        random_state=tst_random_state\n",
    "    )\n",
    "    splits_all = k_fold_all.split(X=ids_all, y=binned_all, groups=binned_all)\n",
    "    \n",
    "    for split_id, (ids_trn_val, ids_tst) in enumerate(splits_all):\n",
    "        df.loc[ids_all[ids_trn_val], f\"Split_{split_id}\"] = \"trn_val\"\n",
    "        df.loc[ids_all[ids_tst], f\"Split_{split_id}\"] = \"tst\"\n",
    "\n",
    "samples = {}\n",
    "for split_id in range(tst_n_splits * tst_n_repeats):\n",
    "    samples[split_id] = {\n",
    "        'test': df.index[df[f\"Split_{split_id}\"] == \"tst\"].values,\n",
    "        'train_validation': df.index[df[f\"Split_{split_id}\"] == \"trn_val\"].values,\n",
    "        'trains': {},\n",
    "        'validations': {},\n",
    "    }\n",
    "\n",
    "    stratify_cat_parts_trnval = {\n",
    "        'Control': df.index[(df['Status'] == 'Control') & (df[f\"Split_{split_id}\"] == 'trn_val')].values,\n",
    "        'ESRD': df.index[(df['Status'] == 'ESRD') & (df[f\"Split_{split_id}\"] == 'trn_val')].values,\n",
    "    }\n",
    "\n",
    "    for part_trnval, ids_trnval in stratify_cat_parts_trnval.items():\n",
    "        trgt_trnval = df.loc[ids_trnval, 'Age'].values\n",
    "        ptp_trnval = np.ptp(trgt_trnval)\n",
    "        num_bins_trnval = 5\n",
    "        bins_trnval = np.linspace(np.min(trgt_trnval) - 0.1 * ptp_trnval, np.max(trgt_trnval) + 0.1 * ptp_trnval, num_bins_trnval + 1)\n",
    "        binned_trnval = np.digitize(trgt_trnval, bins_trnval) - 1\n",
    "        unique_trnval, counts_trnval = np.unique(binned_trnval, return_counts=True)\n",
    "        k_fold_trnval = RepeatedStratifiedKFold(\n",
    "            n_splits=val_n_splits,\n",
    "            n_repeats=val_n_repeats,\n",
    "            random_state=val_random_state\n",
    "        )\n",
    "        splits_trnval = k_fold_trnval.split(X=ids_trnval, y=binned_trnval, groups=binned_trnval)\n",
    "        \n",
    "        for fold_id, (ids_trn, ids_val) in enumerate(splits_trnval):\n",
    "            df.loc[ids_trnval[ids_trn], f\"Split_{split_id}_Fold_{fold_id}\"] = \"trn\"\n",
    "            df.loc[ids_trnval[ids_val], f\"Split_{split_id}_Fold_{fold_id}\"] = \"val\"\n",
    "         \n",
    "    for fold_id in range(val_n_splits * val_n_repeats):\n",
    "        samples[split_id]['trains'][fold_id] = df.index[df[f\"Split_{split_id}_Fold_{fold_id}\"] == \"trn\"].values\n",
    "        samples[split_id]['validations'][fold_id] = df.index[df[f\"Split_{split_id}_Fold_{fold_id}\"] == \"val\"].values\n",
    "\n",
    "    samples[split_id]['cv_indexes'] = [\n",
    "        (\n",
    "            np.where(df.index[df[f\"Split_{split_id}\"] == \"trn_val\"].isin(df.index[(df[f\"Split_{split_id}\"] == \"trn_val\") & (df[f\"Split_{split_id}_Fold_{i}\"] == 'trn')]))[0],\n",
    "            np.where(df.index[df[f\"Split_{split_id}\"] == \"trn_val\"].isin(df.index[(df[f\"Split_{split_id}\"] == \"trn_val\") & (df[f\"Split_{split_id}_Fold_{i}\"] == 'val')]))[0],\n",
    "        )\n",
    "        for i in range(val_n_splits * val_n_repeats)\n",
    "    ]\n",
    "    \n",
    "# Chekning for non-intersection\n",
    "for split_id in range(tst_n_splits * tst_n_repeats):\n",
    "    for fold_id in range(val_n_splits * val_n_repeats):\n",
    "        test_samples = samples[split_id]['test']\n",
    "        train_samples = samples[split_id]['trains'][fold_id]\n",
    "        validation_samples = samples[split_id]['validations'][fold_id]\n",
    "\n",
    "        intxns = {\n",
    "            'train_validation': set.intersection(set(train_samples), set(validation_samples)),\n",
    "            'validation_test': set.intersection(set(validation_samples), set(test_samples)),\n",
    "            'train_test': set.intersection(set(train_samples), set(test_samples))\n",
    "        }\n",
    "        \n",
    "        for intxn_name, intxn_samples in intxns.items():\n",
    "            if len(intxn_samples) > 0:\n",
    "                raise ValueError(f\"Non-zero {intxn_name} intersection ({len(intxn_samples)}) for {split_id} Split and {fold_id} Fold!\")\n",
    "\n",
    "with open(f\"{path_data}/stratification.pickle\", 'wb') as handle:\n",
    "    pickle.dump(samples, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{path_data}/stratification.pickle\", 'rb') as handle:\n",
    "    samples = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load PytorchTabular configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data, Trainer, Optimizer configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_configs = f\"{path_root}/configs/immuno-regression\"\n",
    "\n",
    "data_config = read_parse_config(f\"{path_configs}/DataConfig.yaml\", DataConfig)\n",
    "trainer_config = read_parse_config(f\"{path_configs}/TrainerConfig.yaml\", TrainerConfig)\n",
    "trainer_config['seed'] = seed\n",
    "trainer_config['checkpoints'] = 'valid_loss'\n",
    "trainer_config['load_best'] = True\n",
    "trainer_config['auto_lr_find'] = False\n",
    "optimizer_config = read_parse_config(f\"{path_configs}/OptimizerConfig.yaml\", OptimizerConfig)\n",
    "\n",
    "lr_find_min_lr = 1e-8\n",
    "lr_find_max_lr = 10\n",
    "lr_find_num_training = 512\n",
    "lr_find_mode = \"exponential\"\n",
    "lr_find_early_stop_threshold = 8.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load default Models configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_archs = ['DANet', 'FTTransformer', 'GANDALF', 'TabNetModel' , 'CategoryEmbeddingModel']\n",
    "configs_models_default = {}\n",
    "configs_models_default['DANet'] = read_parse_config(f\"{path_configs}/models/DANetConfig.yaml\", DANetConfig)\n",
    "configs_models_default['FTTransformer'] = read_parse_config(f\"{path_configs}/models/FTTransformerConfig.yaml\", FTTransformerConfig)\n",
    "configs_models_default['GANDALF'] = read_parse_config(f\"{path_configs}/models/GANDALFConfig.yaml\", GANDALFConfig)\n",
    "configs_models_default['TabNetModel'] = read_parse_config(f\"{path_configs}/models/TabNetModelConfig.yaml\", TabNetModelConfig)\n",
    "configs_models_default['CategoryEmbeddingModel'] = read_parse_config(f\"{path_configs}/models/CategoryEmbeddingModelConfig.yaml\", CategoryEmbeddingModelConfig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training immunomarkers models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optuna params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TPE sampler\n",
    "n_trials = 512\n",
    "opt_seed = seed\n",
    "n_startup_trials = 128\n",
    "n_ei_candidates = 16\n",
    "\n",
    "# Init optimization metrics with directions\n",
    "opt_parts = ['test', 'validation']\n",
    "opt_metrics = [('mean_absolute_error', 'minimize'), ('pearson_corrcoef', 'maximize')]\n",
    "opt_directions = []\n",
    "for part in opt_parts:\n",
    "    for metric_pair in opt_metrics:\n",
    "        opt_directions.append(f\"{metric_pair[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation and Hyperparameter optimization training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop for immunomarkers\n",
    "for imm in imms:\n",
    "    \n",
    "    feats = df_feats[imm].to_list()\n",
    "    data_config['target'] = [imm]\n",
    "    data_config['continuous_cols'] = feats\n",
    "    \n",
    "    path_ckpts = f\"{path_root}/logs/Immunomarkers/{imm}\"\n",
    "    pathlib.Path(path_ckpts).mkdir(parents=True, exist_ok=True)\n",
    "    trainer_config['checkpoints_path'] = path_ckpts\n",
    "    \n",
    "    # Dataframes with results\n",
    "    dfs_results = []\n",
    "    \n",
    "    # Loop for train-validation/test splits\n",
    "    for split_id, split_dict in samples.items():\n",
    "        # Loop for train/validation folds\n",
    "        for fold_id in split_dict['trains']:\n",
    "            \n",
    "            test = df.loc[split_dict['test'], feats + [imm]]\n",
    "            train = df.loc[split_dict['trains'][fold_id], feats + [imm]]\n",
    "            validation = df.loc[split_dict['validations'][fold_id], feats + [imm]]\n",
    "            \n",
    "            # Loop for models archs\n",
    "            for m_arch in models_archs:\n",
    "                \n",
    "                tabular_model_default = TabularModel(\n",
    "                    data_config=data_config,\n",
    "                    model_config=configs_models_default[m_arch],\n",
    "                    optimizer_config=optimizer_config,\n",
    "                    trainer_config=trainer_config,\n",
    "                    verbose=False,\n",
    "                )\n",
    "                datamodule = tabular_model_default.prepare_dataloader(train=train, validation=validation, seed=seed)\n",
    "                \n",
    "                trials_results = []\n",
    "                study = optuna.create_study(\n",
    "                    study_name=f\"{imm}_{split_id}_{fold_id}_{m_arch}\",\n",
    "                    sampler=optuna.samplers.TPESampler(\n",
    "                        n_startup_trials=n_startup_trials,\n",
    "                        n_ei_candidates=n_ei_candidates,\n",
    "                        seed=opt_seed,\n",
    "                    ),\n",
    "                    directions=opt_directions\n",
    "                )\n",
    "                study.optimize(\n",
    "                    func=lambda trial: train_hyper_opt(\n",
    "                        trial=trial,\n",
    "                        trials_results=trials_results,\n",
    "                        opt_metrics=opt_metrics,\n",
    "                        opt_parts=opt_parts,\n",
    "                        model_config_default=configs_models_default[m_arch],\n",
    "                        data_config_default=data_config,\n",
    "                        optimizer_config_default=optimizer_config,\n",
    "                        trainer_config_default=trainer_config,\n",
    "                        experiment_config_default=None,\n",
    "                        train=train,\n",
    "                        validation=validation,\n",
    "                        test=test,\n",
    "                        datamodule=datamodule,\n",
    "                        min_lr=lr_find_min_lr,\n",
    "                        max_lr=lr_find_max_lr,\n",
    "                        num_training=lr_find_num_training,\n",
    "                        mode=lr_find_mode,\n",
    "                        early_stop_threshold=lr_find_early_stop_threshold\n",
    "                    ), \n",
    "                    n_trials=n_trials, \n",
    "                    show_progress_bar=False\n",
    "                )\n",
    "                df_trials = pd.DataFrame(trials_results)\n",
    "                df_trials['split_id'] = split_id\n",
    "                df_trials['fold_id'] = fold_id\n",
    "                dfs_results.append(df_trials)\n",
    "    \n",
    "    # Resulting Dataframe for immunomarker\n",
    "    df_results = pd.concat(dfs_results)            \n",
    "    df_results.sort_values(by=['test_loss'], ascending=[True], inplace=True)\n",
    "    df_results.to_excel(f\"{path_ckpts}/results.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_epi_imm_corr = pd.DataFrame(index=imms, columns=list(range(1, 101)))\n",
    "for imm in imms:\n",
    "    corrs = []\n",
    "    for cpg in df_feats[imm]:\n",
    "        res = stats.pearsonr(df[imm], df[cpg], alternative='two-sided')\n",
    "        corrs.append(abs(res.statistic))\n",
    "    df_epi_imm_corr.loc[imm, :] = sorted(corrs, reverse=True)\n",
    "    \n",
    "df_fig = df_epi_imm_corr.astype(float)\n",
    "sns.set_theme(style='ticks', font_scale=1.0)\n",
    "fig, ax = plt.subplots(figsize=(30, 10))\n",
    "heatmap = sns.heatmap(\n",
    "    df_fig,\n",
    "    annot=False,\n",
    "    cmap='hot',\n",
    "    linewidth=0.1,\n",
    "    linecolor='black',\n",
    "    cbar_kws={\n",
    "        'orientation': 'horizontal',\n",
    "        'location': 'top',\n",
    "        'fraction': 0.05,\n",
    "        'pad': 0.025,\n",
    "        'aspect': 60\n",
    "    },\n",
    "    annot_kws={\"size\": 12},\n",
    "    ax=ax\n",
    ")\n",
    "ax.set_xlabel('Top CpGs')\n",
    "ax.set_ylabel('')\n",
    "heatmap_pos = heatmap.get_position()\n",
    "ax.figure.axes[-1].set_title(fr\"|Pearson $\\rho$|\", fontsize='large')\n",
    "ax.figure.axes[-1].tick_params(labelsize='large')\n",
    "for spine in ax.figure.axes[-1].spines.values():\n",
    "    spine.set_linewidth(1)\n",
    "plt.savefig(f\"{path_plots}/imms_cpgs_correlation.png\", bbox_inches='tight', dpi=200)\n",
    "plt.savefig(f\"{path_plots}/imms_cpgs_correlation.pdf\", bbox_inches='tight')\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = 4 * 3\n",
    "n_cols = 8\n",
    "fig_height = 20\n",
    "fig_width = 35\n",
    "\n",
    "imm_colors = distinctipy.get_colors(n_colors=len(imms), exclude_colors=[mcolors.hex2color(mcolors.CSS4_COLORS['gray'])], rng=42)\n",
    "\n",
    "sns.set_theme(style='ticks')\n",
    "fig, axs = plt.subplots(n_rows, n_cols, figsize=(fig_width, fig_height), height_ratios=[0.2, 0.8, 0.2]*4, gridspec_kw={'wspace':0.35, 'hspace': 0.05}, sharey=False, sharex=False)\n",
    "\n",
    "for imm_id, imm in enumerate(imms):\n",
    "    imm_color = imm_colors[imm_id]\n",
    "    imm_metrics = pd.read_excel(f\"{path_root}/models/Immunomarkers/{imm}/metrics.xlsx\", index_col=0)\n",
    "    with open(f\"{path_root}/models/Immunomarkers/{imm}/config.yml\") as f:\n",
    "        imm_config = yaml.safe_load(f)\n",
    "    imm_df = pd.read_excel(f\"{path_root}/models/Immunomarkers/{imm}/df.xlsx\", index_col=0)\n",
    "    imm_df.rename(columns={f\"{imm}_log\": imm}, inplace=True)\n",
    "    \n",
    "    row_id, col_id = divmod(imm_id, n_cols)\n",
    "    row_id_table = row_id * 3\n",
    "    row_id_scatter = row_id * 3 + 1\n",
    "    row_id_empty = row_id * 3 + 2\n",
    "\n",
    "    q01 = df[imm].quantile(0.01)\n",
    "    q99 = df[imm].quantile(0.99)\n",
    "\n",
    "    df_metrics = pd.DataFrame(index=['MAE', fr\"Pearson $\\mathbf{{\\rho}}$\"], columns=['Train', 'Validation', 'Test'])\n",
    "    df_metrics.at['MAE', 'Train'] = f\"{imm_metrics.at['Train', 'mean_absolute_error']:0.3f}\"\n",
    "    df_metrics.at['MAE', 'Validation'] = f\"{imm_metrics.at['Validation', 'mean_absolute_error']:0.3f}\"\n",
    "    df_metrics.at['MAE', 'Test'] = f\"{imm_metrics.at['Test', 'mean_absolute_error']:0.3f}\"\n",
    "    df_metrics.at[fr\"Pearson $\\mathbf{{\\rho}}$\", 'Train'] = f\"{imm_metrics.at['Train', 'pearson_corrcoef']:0.3f}\"\n",
    "    df_metrics.at[fr\"Pearson $\\mathbf{{\\rho}}$\", 'Validation'] = f\"{imm_metrics.at['Validation', 'pearson_corrcoef']:0.3f}\"\n",
    "    df_metrics.at[fr\"Pearson $\\mathbf{{\\rho}}$\", 'Test'] = f\"{imm_metrics.at['Test', 'pearson_corrcoef']:0.3f}\"\n",
    "    \n",
    "    col_defs = [\n",
    "        ColumnDefinition(\n",
    "            name=\"index\",\n",
    "            title=imm_config['_model_name'].replace('Model', ''),\n",
    "            textprops={\"ha\": \"center\", \"weight\": \"bold\"},\n",
    "            width=2.5,\n",
    "            group=fr\"$\\mathbf{{{imm}}}$\",\n",
    "        ),\n",
    "        ColumnDefinition(\n",
    "            name=\"Train\",\n",
    "            textprops={\"ha\": \"left\"},\n",
    "            width=1.5,\n",
    "            border=\"left\",\n",
    "            group=fr\"$\\mathbf{{{imm}}}$\",\n",
    "        ),\n",
    "        ColumnDefinition(\n",
    "            name=\"Validation\",\n",
    "            textprops={\"ha\": \"left\"},\n",
    "            width=1.5,\n",
    "            group=fr\"$\\mathbf{{{imm}}}$\",\n",
    "        ),\n",
    "        ColumnDefinition(\n",
    "            name=\"Test\",\n",
    "            textprops={\"ha\": \"left\"},\n",
    "            width=1.5,\n",
    "            group=fr\"$\\mathbf{{{imm}}}$\",\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    table = Table(\n",
    "        df_metrics,\n",
    "        column_definitions=col_defs,\n",
    "        row_dividers=True,\n",
    "        footer_divider=False,\n",
    "        ax=axs[row_id_table, col_id],\n",
    "        textprops={\"fontsize\": 8},\n",
    "        row_divider_kw={\"linewidth\": 1, \"linestyle\": (0, (1, 1))},\n",
    "        col_label_divider_kw={\"linewidth\": 1, \"linestyle\": \"-\"},\n",
    "        column_border_kw={\"linewidth\": 1, \"linestyle\": \"-\"},\n",
    "    ).autoset_fontcolors(colnames=['Train', 'Validation', 'Test'])\n",
    "\n",
    "    kdeplot = sns.kdeplot(\n",
    "        data=imm_df.loc[imm_df['Group'] != 'Test', :],\n",
    "        x=imm,\n",
    "        y='Prediction',\n",
    "        fill=True,\n",
    "        cbar=False,\n",
    "        color=imm_color,\n",
    "        cut=0,\n",
    "        legend=False,\n",
    "        ax=axs[row_id_scatter, col_id]\n",
    "    )\n",
    "    scatter = sns.scatterplot(\n",
    "        data=imm_df.loc[imm_df['Group'] == 'Test', :],\n",
    "        x=imm,\n",
    "        y=\"Prediction\",\n",
    "        linewidth=0.5,\n",
    "        alpha=0.8,\n",
    "        edgecolor=\"k\",\n",
    "        s=35,\n",
    "        color=imm_color,\n",
    "        ax=axs[row_id_scatter, col_id],\n",
    "    )\n",
    "    axs[row_id_scatter, col_id].axline((0, 0), slope=1, color=\"black\", linestyle=\":\")\n",
    "    axs[row_id_scatter, col_id].set_xlim(q01, q99)\n",
    "    axs[row_id_scatter, col_id].set_ylim(q01, q99)\n",
    "    axs[row_id_scatter, col_id].set_xlabel(imm, color=imm_color, path_effects=[pe.withStroke(linewidth=1.0, foreground=\"black\")])\n",
    "    \n",
    "    axs[row_id_empty, col_id].axis('off')\n",
    "\n",
    "fig.tight_layout()    \n",
    "fig.savefig(f\"{path_plots}/imms_models.png\", bbox_inches='tight', dpi=200)\n",
    "fig.savefig(f\"{path_plots}/imms_models.pdf\", bbox_inches='tight')\n",
    "plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
