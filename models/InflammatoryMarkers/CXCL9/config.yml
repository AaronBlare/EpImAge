target:
- CXCL9_log
continuous_cols:
- cg22880770
- cg12442242
- cg24766229
- cg07192612
- cg08561469
- cg21817284
- cg17287553
- cg16867657
- cg01479768
- cg13598865
- cg24718773
- cg04885885
- cg24028809
- cg17246929
- cg16444607
- cg25809905
- cg07631407
- cg22869634
- cg23897733
- cg22538054
- cg09809672
- cg00581043
- cg01431992
- cg17598937
- cg21814178
- cg20045888
- cg24914313
- cg23528142
- cg20814026
- cg12893780
- cg08721840
- cg18145105
- cg12419932
- cg12747467
- cg26153045
- cg12074485
- cg09383816
- cg09931909
- cg06828730
- cg14209299
- cg01565659
- cg27471901
- cg13359998
- cg13316472
- cg17716961
- cg23970785
- cg26132493
- cg24064173
- cg15531930
- cg09046427
- cg01807377
- ch.12.46508471F
- cg01410876
- cg22843684
- cg03521728
- cg10438391
- cg17946713
- cg16976189
- cg06163904
- cg07401394
- cg11967431
- cg08876039
- cg25267930
- cg01553661
- cg08346159
- cg01607569
- cg04452362
- cg15660740
- cg02390329
- cg16048517
- cg20271985
- cg18013336
- cg14872952
- cg11341610
- cg20481110
- cg17804348
- cg04317492
- cg19102955
- cg03992638
- cg19930737
- cg15392147
- cg21408360
- cg24749559
- cg07134033
- cg06500161
- cg05370555
- cg19893929
- cg15268007
- cg23030863
- cg16844053
- cg02729030
- cg19995539
- cg03549739
- cg12186410
- cg15700661
- cg01447660
- cg18117367
- cg01185921
- cg07205374
- cg12597558
categorical_cols: []
date_columns: []
encode_date_columns: true
validation_split: 0.25
continuous_feature_transform: null
normalize_continuous_features: true
quantile_noise: 0
num_workers: 0
pin_memory: true
handle_unknown_categories: true
handle_missing_values: true
task: regression
head: LinearHead
head_config:
  layers: ''
  activation: ReLU
  dropout: 0.2343821155366096
  use_batch_norm: false
  initialization: xavier
embedding_dims: null
embedding_dropout: 0.0
batch_norm_continuous_input: true
learning_rate: 0.0050505785065465755
loss: L1Loss
metrics:
- mean_absolute_error
- pearson_corrcoef
metrics_prob_input:
- false
- false
metrics_params:
- {}
- {}
target_range: null
virtual_batch_size: null
seed: 1337
_module_src: models.ft_transformer
_model_name: FTTransformerModel
_backbone_name: FTTransformerBackbone
_config_name: FTTransformerConfig
input_embed_dim: 32
embedding_initialization: kaiming_uniform
embedding_bias: true
share_embedding: false
share_embedding_strategy: fraction
shared_embedding_fraction: 0.25
attn_feature_importance: false
num_heads: 8
num_attn_blocks: 4
transformer_head_dim: null
attn_dropout: 0.048667399247769964
add_norm_dropout: 0.18468960407206414
ff_dropout: 0.19298611047153327
ff_hidden_multiplier: 4
transformer_activation: GEGLU
batch_size: 1024
data_aware_init_batch_size: 2000
fast_dev_run: false
max_epochs: 1000
min_epochs: 1
max_time: null
accelerator: auto
devices: -1
devices_list: null
accumulate_grad_batches: 1
auto_lr_find: false
auto_select_gpus: true
check_val_every_n_epoch: 1
gradient_clip_val: 0.0
overfit_batches: 0.0
deterministic: false
profiler: null
early_stopping: valid_loss
early_stopping_min_delta: 1.0e-06
early_stopping_mode: min
early_stopping_patience: 50
early_stopping_kwargs: {}
checkpoints: valid_loss
checkpoints_path: D:/YandexDisk/Work/bbd/immunology/003_EpImAge/imp_source(imm)_method(knn)_params(5)/no_harm/mrmr_100/CXCL9/pytorch_tabular
checkpoints_every_n_epochs: 5
checkpoints_name: null
checkpoints_mode: min
checkpoints_save_top_k: 1
checkpoints_kwargs: {}
load_best: true
track_grad_norm: -1
progress_bar: none
precision: 32
trainer_kwargs: {}
optimizer: Adam
optimizer_params:
  weight_decay: 2.716641440872644e-06
lr_scheduler: ReduceLROnPlateau
lr_scheduler_params:
  mode: min
  factor: 0.6875470427300208
  patience: 25
  threshold: 0.0001
lr_scheduler_monitor_metric: valid_loss
enable_checkpointing: true
