target:
- IL5_log
continuous_cols:
- cg17936867
- cg03806069
- cg06032337
- cg23071186
- cg02775254
- cg09651654
- cg07970948
- cg07039378
- cg01223225
- cg00293940
- cg10482057
- cg20489239
- cg06693575
- cg21695935
- cg25457927
- cg15782228
- cg10435486
- cg10712044
- cg07290739
- cg01599925
- cg13848802
- cg03634833
- cg21721825
- cg02584939
- cg02383835
- cg22498365
- cg04862290
- cg04599631
- cg17445936
- cg02357491
- cg18179491
- cg00526772
- cg04983687
- cg17382939
- cg19001845
- cg19368625
- cg23756872
- cg05044994
- cg08967764
- cg08429705
- cg13038025
- cg17321214
- cg00985115
- cg26989323
- cg00585551
- cg22823146
- cg10312186
- cg00787180
- cg24471210
- cg17213699
- cg06631160
- cg23802887
- cg19078226
- cg10232936
- cg10539670
- cg03599590
- cg03165014
- cg06812586
- cg09552399
- cg02613034
- cg07502936
- cg17143192
- cg14240646
- cg10456168
- cg08997352
- cg07307422
- cg17016524
- cg23513363
- cg01245423
- cg05294307
- cg04155600
- cg02367916
- cg02287939
- cg01479031
- cg07691761
- cg05597908
- cg01572989
- cg02737840
- cg18663091
- cg02147989
- cg23743670
- cg15202609
- cg01243312
- cg22168512
- cg14102267
- cg11268327
- cg13011928
- cg23110005
- cg24323768
- cg01697732
- cg20252997
- cg05321808
- cg18355133
- cg02746781
- cg10158369
- cg12854458
- cg21845373
- cg03649353
- cg13245593
- cg24518943
categorical_cols: []
date_columns: []
encode_date_columns: true
validation_split: 0.25
continuous_feature_transform: box-cox
normalize_continuous_features: true
quantile_noise: 0
num_workers: 0
pin_memory: true
handle_unknown_categories: true
handle_missing_values: true
task: regression
head: LinearHead
head_config:
  layers: ''
  activation: ReLU
  dropout: 0.045238141449312826
  use_batch_norm: false
  initialization: xavier
embedding_dims: null
embedding_dropout: 0.0
batch_norm_continuous_input: true
learning_rate: 0.004675811570988757
loss: L1Loss
metrics:
- mean_absolute_error
- pearson_corrcoef
metrics_prob_input:
- false
- false
metrics_params:
- {}
- {}
target_range: null
virtual_batch_size: null
seed: 1337
_module_src: models.ft_transformer
_model_name: FTTransformerModel
_backbone_name: FTTransformerBackbone
_config_name: FTTransformerConfig
input_embed_dim: 32
embedding_initialization: kaiming_uniform
embedding_bias: true
share_embedding: false
share_embedding_strategy: fraction
shared_embedding_fraction: 0.25
attn_feature_importance: false
num_heads: 2
num_attn_blocks: 2
transformer_head_dim: null
attn_dropout: 0.1602382873889649
add_norm_dropout: 0.1698400072996277
ff_dropout: 0.21495451895530068
ff_hidden_multiplier: 4
transformer_activation: GEGLU
batch_size: 1024
data_aware_init_batch_size: 2000
fast_dev_run: false
max_epochs: 1000
min_epochs: 1
max_time: null
accelerator: auto
devices: -1
devices_list: null
accumulate_grad_batches: 1
auto_lr_find: false
auto_select_gpus: true
check_val_every_n_epoch: 1
gradient_clip_val: 0.0
overfit_batches: 0.0
deterministic: false
profiler: null
early_stopping: valid_loss
early_stopping_min_delta: 1.0e-06
early_stopping_mode: min
early_stopping_patience: 50
early_stopping_kwargs: {}
checkpoints: valid_loss
checkpoints_path: D:/YandexDisk/Work/bbd/immunology/003_EpImAge/imp_source(imm)_method(knn)_params(5)/no_harm/mrmr_100/IL5/pytorch_tabular
checkpoints_every_n_epochs: 5
checkpoints_name: null
checkpoints_mode: min
checkpoints_save_top_k: 1
checkpoints_kwargs: {}
load_best: true
track_grad_norm: -1
progress_bar: none
precision: 32
trainer_kwargs: {}
optimizer: Adam
optimizer_params:
  weight_decay: 1.0397412673557933e-06
lr_scheduler: ReduceLROnPlateau
lr_scheduler_params:
  mode: min
  factor: 0.8809301462798155
  patience: 25
  threshold: 0.0001
lr_scheduler_monitor_metric: valid_loss
enable_checkpointing: true
