target:
- PDGFA_log
continuous_cols:
- cg07095205
- cg23813681
- cg06741336
- cg06143362
- cg22678073
- cg26954695
- cg14221644
- cg03584693
- cg13952002
- cg09938634
- cg11188618
- cg26341268
- cg17811663
- cg01302066
- cg08666915
- cg21724239
- cg05307070
- cg17929687
- cg01152624
- cg25345648
- cg14650175
- cg24931092
- cg04297660
- cg05371332
- cg07123730
- cg18952506
- cg24593630
- cg19119577
- cg04600092
- cg16078060
- cg06455375
- cg21717369
- cg10923855
- cg05940536
- cg24024528
- cg01729262
- cg02016764
- ch.1.2554598F
- cg02520270
- cg02960500
- cg00714078
- cg09536337
- cg26250558
- cg11166287
- cg02758987
- cg21001780
- cg17513697
- cg13213536
- cg16983817
- cg04380118
- cg19718662
- cg24470734
- cg13688974
- cg23501610
- cg26090739
- cg19701084
- cg10242541
- cg26463106
- cg05668996
- cg14665629
- cg25546118
- cg07364657
- cg05593655
- cg00059374
- cg05783233
- cg18836267
- cg14085262
- cg19435526
- cg25628310
- cg05366050
- cg27558387
- cg02328113
- cg06657721
- cg19820070
- cg05822022
- cg15799967
- cg04125341
- cg06151432
- cg08898055
- cg10948061
- cg12033297
- cg16397629
- cg08539737
- cg12718519
- cg00013475
- cg03077073
- cg07119172
- cg08859513
- cg02635209
- cg23585420
- cg18251035
- cg09990613
- cg01752203
- cg06982272
- cg04247135
- cg17452570
- cg21920539
- cg07888347
- cg15546638
- cg20145276
categorical_cols: []
date_columns: []
encode_date_columns: true
validation_split: 0.25
continuous_feature_transform: null
normalize_continuous_features: true
quantile_noise: 0
num_workers: 0
pin_memory: true
handle_unknown_categories: true
handle_missing_values: true
task: regression
head: LinearHead
head_config:
  layers: ''
  activation: ReLU
  dropout: 0.05101158392521718
  use_batch_norm: false
  initialization: xavier
embedding_dims: null
embedding_dropout: 0.0
batch_norm_continuous_input: true
learning_rate: 0.004832005676480831
loss: L1Loss
metrics:
- mean_absolute_error
- pearson_corrcoef
metrics_prob_input:
- false
- false
metrics_params:
- {}
- {}
target_range: null
virtual_batch_size: null
seed: 1337
_module_src: models.ft_transformer
_model_name: FTTransformerModel
_backbone_name: FTTransformerBackbone
_config_name: FTTransformerConfig
input_embed_dim: 32
embedding_initialization: kaiming_uniform
embedding_bias: true
share_embedding: false
share_embedding_strategy: fraction
shared_embedding_fraction: 0.25
attn_feature_importance: false
num_heads: 2
num_attn_blocks: 2
transformer_head_dim: null
attn_dropout: 0.22961242585535976
add_norm_dropout: 0.1783710598876679
ff_dropout: 0.19006874805940085
ff_hidden_multiplier: 4
transformer_activation: GEGLU
batch_size: 1024
data_aware_init_batch_size: 2000
fast_dev_run: false
max_epochs: 1000
min_epochs: 1
max_time: null
accelerator: auto
devices: -1
devices_list: null
accumulate_grad_batches: 1
auto_lr_find: false
auto_select_gpus: true
check_val_every_n_epoch: 1
gradient_clip_val: 0.0
overfit_batches: 0.0
deterministic: false
profiler: null
early_stopping: valid_loss
early_stopping_min_delta: 1.0e-06
early_stopping_mode: min
early_stopping_patience: 50
early_stopping_kwargs: {}
checkpoints: valid_loss
checkpoints_path: D:/YandexDisk/Work/bbd/immunology/003_EpImAge/imp_source(imm)_method(knn)_params(5)/no_harm/mrmr_100/PDGFA/pytorch_tabular
checkpoints_every_n_epochs: 5
checkpoints_name: null
checkpoints_mode: min
checkpoints_save_top_k: 1
checkpoints_kwargs: {}
load_best: true
track_grad_norm: -1
progress_bar: none
precision: 32
trainer_kwargs: {}
optimizer: Adam
optimizer_params:
  weight_decay: 1.8689774654483847e-08
lr_scheduler: ReduceLROnPlateau
lr_scheduler_params:
  mode: min
  factor: 0.7420307435279071
  patience: 25
  threshold: 0.0001
lr_scheduler_monitor_metric: valid_loss
enable_checkpointing: true
