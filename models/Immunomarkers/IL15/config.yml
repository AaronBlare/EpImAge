target:
- IL15_log
continuous_cols:
- cg13770461
- cg10664618
- cg14999852
- cg22131825
- cg07449543
- cg08865522
- cg05571310
- cg10741399
- cg08796240
- cg02954704
- cg14755900
- cg00101154
- cg05000199
- cg04595372
- cg09569990
- cg04131943
- cg12415116
- cg13048591
- cg22860607
- cg21653586
- cg10879244
- cg10773587
- cg21634951
- cg17983632
- cg04039957
- cg08260052
- cg02136201
- cg26510723
- cg07545627
- cg19611817
- cg12813394
- cg17245337
- cg01412379
- cg10723629
- cg04185310
- cg08750432
- cg09218130
- cg03182917
- cg18072522
- cg06323957
- cg26924408
- cg13601997
- cg11638980
- cg12581244
- cg09760387
- cg16589663
- cg21812850
- cg03840849
- cg06915524
- cg07592358
- cg26570804
- cg02218260
- cg00040103
- cg04085025
- cg22822219
- cg18430645
- cg01108476
- cg05739816
- cg15627871
- cg16729832
- cg06376402
- cg00502241
- cg27308967
- cg09336899
- cg02015876
- cg26186134
- cg26365014
- cg20746459
- cg07560408
- cg20825710
- cg04954225
- cg01749778
- cg09233395
- cg13770865
- cg16911275
- cg00007076
- cg25059994
- cg14884373
- cg10207042
- cg02351840
- cg20462129
- cg14709460
- cg21865751
- cg25668117
- cg12114260
- cg18236571
- cg18313094
- cg05663573
- cg21230284
- cg10839997
- cg23510415
- cg10123247
- cg24238995
- cg00106591
- cg21384371
- cg04196119
- cg18813182
- cg18808076
- cg22453033
- cg07553761
categorical_cols: []
date_columns: []
encode_date_columns: true
validation_split: 0.25
continuous_feature_transform: null
normalize_continuous_features: true
quantile_noise: 0
num_workers: 0
pin_memory: true
handle_unknown_categories: true
handle_missing_values: true
task: regression
head: LinearHead
head_config:
  layers: ''
  activation: ReLU
  dropout: 0.20526183117249913
  use_batch_norm: false
  initialization: xavier
embedding_dims: null
embedding_dropout: 0.0
batch_norm_continuous_input: true
learning_rate: 0.00214521268458654
loss: L1Loss
metrics:
- mean_absolute_error
- pearson_corrcoef
metrics_prob_input:
- false
- false
metrics_params:
- {}
- {}
target_range: null
virtual_batch_size: null
seed: 1337
_module_src: models.ft_transformer
_model_name: FTTransformerModel
_backbone_name: FTTransformerBackbone
_config_name: FTTransformerConfig
input_embed_dim: 32
embedding_initialization: kaiming_uniform
embedding_bias: true
share_embedding: false
share_embedding_strategy: fraction
shared_embedding_fraction: 0.25
attn_feature_importance: false
num_heads: 16
num_attn_blocks: 6
transformer_head_dim: null
attn_dropout: 0.015678018314544614
add_norm_dropout: 0.005695075554039856
ff_dropout: 0.232311674772833
ff_hidden_multiplier: 4
transformer_activation: GEGLU
batch_size: 1024
data_aware_init_batch_size: 2000
fast_dev_run: false
max_epochs: 1000
min_epochs: 1
max_time: null
accelerator: auto
devices: -1
devices_list: null
accumulate_grad_batches: 1
auto_lr_find: false
auto_select_gpus: true
check_val_every_n_epoch: 1
gradient_clip_val: 0.0
overfit_batches: 0.0
deterministic: false
profiler: null
early_stopping: valid_loss
early_stopping_min_delta: 1.0e-06
early_stopping_mode: min
early_stopping_patience: 50
early_stopping_kwargs: {}
checkpoints: valid_loss
checkpoints_path: D:/YandexDisk/Work/bbd/immunology/003_EpImAge/imp_source(imm)_method(knn)_params(5)/no_harm/mrmr_100/IL15/pytorch_tabular
checkpoints_every_n_epochs: 5
checkpoints_name: null
checkpoints_mode: min
checkpoints_save_top_k: 1
checkpoints_kwargs: {}
load_best: true
track_grad_norm: -1
progress_bar: none
precision: 32
trainer_kwargs: {}
optimizer: Adam
optimizer_params:
  weight_decay: 4.694940693057749e-05
lr_scheduler: ReduceLROnPlateau
lr_scheduler_params:
  mode: min
  factor: 0.8807582893392354
  patience: 25
  threshold: 0.0001
lr_scheduler_monitor_metric: valid_loss
enable_checkpointing: true
