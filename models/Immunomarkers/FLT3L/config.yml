target:
- FLT3L_log
continuous_cols:
- cg25679870
- cg04349084
- cg17869647
- cg13537416
- cg09194930
- cg06197930
- cg09386619
- cg20278439
- cg09076339
- cg01847719
- cg11562309
- cg24714561
- cg13560853
- cg03980745
- cg07732336
- cg23858286
- cg13596081
- cg12145080
- cg04357965
- cg11851098
- cg01136380
- cg00019118
- cg19521934
- cg12090001
- cg13417268
- cg22348299
- cg11573219
- cg20449738
- cg05063597
- cg24548498
- cg21121336
- cg18497550
- cg22106810
- cg04194294
- cg22896991
- cg03345093
- cg16638945
- cg12937434
- cg15472784
- cg02982793
- cg14549878
- cg11779204
- cg12203636
- cg04232649
- cg12397252
- cg05139709
- cg26863750
- cg09515947
- cg12927990
- cg11162118
- cg19339021
- cg08155465
- cg00017221
- cg03529432
- cg04993975
- cg09435617
- cg09912667
- cg27096779
- cg05200925
- cg07829379
- cg13854498
- cg08230332
- cg18265147
- cg22815953
- cg22201573
- cg13331940
- cg06599209
- cg05657618
- cg25367304
- cg25693302
- cg03336334
- cg00345443
- cg10589249
- cg25683325
- cg18107144
- cg11854806
- cg24154839
- cg06766427
- cg11372563
- cg15548613
- cg06572093
- cg19350020
- cg22893405
- cg13274149
- cg05693127
- cg11231735
- cg20231299
- cg14785381
- cg00445523
- cg17381692
- cg01830883
- cg01236616
- cg26134248
- cg26747317
- cg08899667
- cg22280671
- cg01347048
- cg17852385
- cg13033853
- cg27407546
categorical_cols: []
date_columns: []
encode_date_columns: true
validation_split: 0.25
continuous_feature_transform: null
normalize_continuous_features: true
quantile_noise: 0
num_workers: 0
pin_memory: true
handle_unknown_categories: true
handle_missing_values: true
task: regression
head: LinearHead
head_config:
  layers: ''
  activation: ReLU
  dropout: 0.0048223312009037095
  use_batch_norm: false
  initialization: xavier
embedding_dims: null
embedding_dropout: 0.0
batch_norm_continuous_input: true
learning_rate: 0.0015911974957640422
loss: L1Loss
metrics:
- mean_absolute_error
- pearson_corrcoef
metrics_prob_input:
- false
- false
metrics_params:
- {}
- {}
target_range: null
virtual_batch_size: null
seed: 1337
_module_src: models.ft_transformer
_model_name: FTTransformerModel
_backbone_name: FTTransformerBackbone
_config_name: FTTransformerConfig
input_embed_dim: 32
embedding_initialization: kaiming_uniform
embedding_bias: true
share_embedding: false
share_embedding_strategy: fraction
shared_embedding_fraction: 0.25
attn_feature_importance: false
num_heads: 8
num_attn_blocks: 12
transformer_head_dim: null
attn_dropout: 0.2499236079871477
add_norm_dropout: 0.04822225700165928
ff_dropout: 0.036789391957742605
ff_hidden_multiplier: 4
transformer_activation: GEGLU
batch_size: 1024
data_aware_init_batch_size: 2000
fast_dev_run: false
max_epochs: 1000
min_epochs: 1
max_time: null
accelerator: auto
devices: -1
devices_list: null
accumulate_grad_batches: 1
auto_lr_find: false
auto_select_gpus: true
check_val_every_n_epoch: 1
gradient_clip_val: 0.0
overfit_batches: 0.0
deterministic: false
profiler: null
early_stopping: valid_loss
early_stopping_min_delta: 1.0e-06
early_stopping_mode: min
early_stopping_patience: 50
early_stopping_kwargs: {}
checkpoints: valid_loss
checkpoints_path: D:/YandexDisk/Work/bbd/immunology/003_EpImAge/imp_source(imm)_method(knn)_params(5)/no_harm/mrmr_100/FLT3L/pytorch_tabular
checkpoints_every_n_epochs: 5
checkpoints_name: null
checkpoints_mode: min
checkpoints_save_top_k: 1
checkpoints_kwargs: {}
load_best: true
track_grad_norm: -1
progress_bar: none
precision: 32
trainer_kwargs: {}
optimizer: Adam
optimizer_params:
  weight_decay: 9.928433937125174e-08
lr_scheduler: ReduceLROnPlateau
lr_scheduler_params:
  mode: min
  factor: 0.8890512281166528
  patience: 25
  threshold: 0.0001
lr_scheduler_monitor_metric: valid_loss
enable_checkpointing: true
