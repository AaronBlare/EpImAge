target:
- CXCL10_log
continuous_cols:
- cg20986370
- cg21828663
- cg13922935
- ch.21.818333F
- cg09140029
- cg14825858
- cg05376954
- cg08662074
- cg01154505
- cg00980776
- cg21649277
- cg02191044
- cg15460093
- cg10985055
- cg10805850
- cg19179910
- cg08517826
- cg02714932
- cg11957130
- cg02013741
- cg20209308
- cg27600265
- cg26749976
- cg21865108
- cg11952714
- cg20982046
- cg26570804
- cg13745964
- cg05890377
- cg02264195
- cg01995743
- cg24718773
- cg05318600
- cg21283926
- cg06739462
- cg22259932
- cg19949441
- cg01159194
- cg18486231
- cg04308167
- cg26635219
- cg25506288
- cg08506401
- cg18410685
- cg21448145
- cg22154293
- cg21069500
- cg15133265
- ch.1.113470988R
- cg26455624
- cg16809762
- cg14372125
- cg02662576
- cg10008970
- cg24904788
- cg16026114
- cg10205310
- cg05014842
- cg17768491
- cg22062555
- cg22488891
- cg02674384
- cg07791427
- cg03944143
- cg02796773
- cg04949608
- cg01915283
- cg25776343
- cg10797944
- cg18931760
- cg16629469
- cg01324550
- cg04671742
- cg15335768
- cg21248188
- cg13562542
- cg00810971
- cg12318316
- cg04121771
- cg03747251
- cg02723063
- cg00210768
- cg03325843
- cg25221207
- cg17333291
- cg05552035
- cg13932286
- cg09971811
- cg00738849
- cg27382568
- cg11059944
- cg00350642
- cg13033858
- cg18293662
- cg01651364
- cg04181032
- cg18883033
- cg09139047
- cg12269138
- cg19279464
categorical_cols: []
date_columns: []
encode_date_columns: true
validation_split: 0.25
continuous_feature_transform: quantile_uniform
normalize_continuous_features: true
quantile_noise: 0
num_workers: 0
pin_memory: true
handle_unknown_categories: true
handle_missing_values: true
task: regression
head: LinearHead
head_config:
  layers: ''
  activation: ReLU
  dropout: 0.19666983605252647
  use_batch_norm: false
  initialization: xavier
embedding_dims: null
embedding_dropout: 0.0
batch_norm_continuous_input: true
learning_rate: 0.009328926472952744
loss: L1Loss
metrics:
- mean_absolute_error
- pearson_corrcoef
metrics_prob_input:
- false
- false
metrics_params:
- {}
- {}
target_range: null
virtual_batch_size: null
seed: 1337
_module_src: models.ft_transformer
_model_name: FTTransformerModel
_backbone_name: FTTransformerBackbone
_config_name: FTTransformerConfig
input_embed_dim: 32
embedding_initialization: kaiming_uniform
embedding_bias: true
share_embedding: false
share_embedding_strategy: fraction
shared_embedding_fraction: 0.25
attn_feature_importance: false
num_heads: 16
num_attn_blocks: 2
transformer_head_dim: null
attn_dropout: 0.010833699261249167
add_norm_dropout: 0.01770549516995529
ff_dropout: 0.03166606547551543
ff_hidden_multiplier: 4
transformer_activation: GEGLU
batch_size: 1024
data_aware_init_batch_size: 2000
fast_dev_run: false
max_epochs: 1000
min_epochs: 1
max_time: null
accelerator: auto
devices: -1
devices_list: null
accumulate_grad_batches: 1
auto_lr_find: false
auto_select_gpus: true
check_val_every_n_epoch: 1
gradient_clip_val: 0.0
overfit_batches: 0.0
deterministic: false
profiler: null
early_stopping: valid_loss
early_stopping_min_delta: 1.0e-06
early_stopping_mode: min
early_stopping_patience: 50
early_stopping_kwargs: {}
checkpoints: valid_loss
checkpoints_path: D:/YandexDisk/Work/bbd/immunology/003_EpImAge/imp_source(imm)_method(knn)_params(5)/no_harm/mrmr_100/CXCL10/pytorch_tabular
checkpoints_every_n_epochs: 5
checkpoints_name: null
checkpoints_mode: min
checkpoints_save_top_k: 1
checkpoints_kwargs: {}
load_best: true
track_grad_norm: -1
progress_bar: none
precision: 32
trainer_kwargs: {}
optimizer: Adam
optimizer_params:
  weight_decay: 1.7605599643009622e-06
lr_scheduler: ReduceLROnPlateau
lr_scheduler_params:
  mode: min
  factor: 0.25142403047869794
  patience: 25
  threshold: 0.0001
lr_scheduler_monitor_metric: valid_loss
enable_checkpointing: true
